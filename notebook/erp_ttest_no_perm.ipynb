{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b5dc97",
   "metadata": {},
   "source": [
    "## Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06961fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "import mne\n",
    "from mne.channels import find_ch_adjacency, make_1020_channel_selections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc08ce4",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'LaughterPassive'\n",
    "subj_list = SUBJ_CLEAN\n",
    "stage = \"epo\"\n",
    "\n",
    "# Select what conditions to compute (str)\n",
    "cond1 = 'LaughPosed'\n",
    "cond2 = 'BaselineZero'\n",
    "cond3 = 'Miss'\n",
    "\n",
    "if cond1 == 'Good' and 'cond3' == 'Miss' :\n",
    "    button_cond = True\n",
    "else :\n",
    "    button_cond = False\n",
    "    \n",
    "conditions = conditions = cond1 + '-' + cond2\n",
    "condition_list = [cond1, cond2]\n",
    "picks = \"meg\" # Select MEG channels\n",
    "\n",
    "roi = 'MLT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2f3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "contrasts_all_subject = []\n",
    "contrasts_all_subject_all_chan = []\n",
    "evoked_baseline = []\n",
    "evoked_condition1 = []\n",
    "\n",
    "for subj in SUBJ_CLEAN :\n",
    "    print(\"processing -->\", subj)\n",
    "    \n",
    "    chan_selected = []\n",
    "    \n",
    "    # TODO : change with AR_epochs\n",
    "    _, path_epochs = get_bids_file(RESULT_PATH, task=task, subj=subj, stage=\"AR_epo\")\n",
    "    epochs = mne.read_epochs(path_epochs, verbose=None)\n",
    "    epochs.apply_baseline(baseline=(None, 0))\n",
    "    \n",
    "    CHAN = epochs.info['ch_names']\n",
    "    \n",
    "    for chan in CHAN  : \n",
    "        if roi in chan : \n",
    "            chan_selected.append(chan)\n",
    "    \n",
    "    epochs_copy = epochs.copy() \n",
    "    epochs_copy.pick_channels(chan_selected)\n",
    "            \n",
    "    #epochs_copy.filter(1, 20)\n",
    "    \n",
    "    # Take nb channel and time\n",
    "    baseline_data = np.zeros((epochs_copy.get_data().shape[1], epochs_copy.get_data().shape[2]))\n",
    "    baseline_roi = mne.EvokedArray(baseline_data, epochs_copy.info, tmin=-0.5, comment='baseline')\n",
    "    \n",
    "    baseline_data_all_chan = np.zeros((epochs.get_data().shape[1], epochs.get_data().shape[2]))\n",
    "    baseline_all_chan = mne.EvokedArray(baseline_data_all_chan, epochs.info, tmin=-0.5, comment='baseline')\n",
    "    \n",
    "    # Compute button press : Combine cond1 & 2\n",
    "    if button_cond == True : \n",
    "        evoked_cond1_roi = mne.combine_evoked([epochs_copy[cond1].average(), epochs_copy[cond3].average()], weights='nave')\n",
    "        evoked_cond1_all_chan = mne.combine_evoked([epochs[cond1].average(), epochs[cond3].average()], weights='nave')\n",
    "\n",
    "    else : \n",
    "        \n",
    "        evoked_cond1_roi = epochs_copy[cond1].average()\n",
    "        evoked_cond1_all_chan = epochs[cond1].average()\n",
    "\n",
    "    evoked_baseline.append(baseline_roi) \n",
    "    evoked_condition1.append(evoked_cond1_roi)\n",
    "    \n",
    "    contrast = mne.combine_evoked([evoked_cond1_roi, baseline_roi], weights=[1, -1])\n",
    "    contrast_all_chan = mne.combine_evoked([evoked_cond1_all_chan, baseline_all_chan], weights=[1, -1])\n",
    "    contrast.pick_types(meg=True, ref_meg=False,  exclude='bads')\n",
    "    \n",
    "    contrasts_all_subject.append(contrast)\n",
    "    contrasts_all_subject_all_chan.append(contrast_all_chan)\n",
    "    \n",
    "# Combine all subject together\n",
    "evokeds = {cond1 : evoked_condition1, cond2 : evoked_baseline}\n",
    "\n",
    "evoked_contrast = mne.combine_evoked(contrasts_all_subject, 'equal')\n",
    "evoked_contrast_all_chan = mne.combine_evoked(contrasts_all_subject_all_chan, 'equal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e8a1e",
   "metadata": {},
   "source": [
    "## Perform paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd3733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-test without correction without clusters\n",
    "\n",
    "time_windows = ((-0.5, 1.5), (0.35, 0.45))\n",
    "index = [\"condition\", \"epoch\", \"time\"]\n",
    "\n",
    "# display the EEG data in Pandas format (first 5 rows)\n",
    "print(epochs.to_data_frame(index=index)[elecs].head())\n",
    "\n",
    "report = \"{elec}, time: {tmin}-{tmax} s; t({df})={t_val:.3f}, p={p:.3f}\"\n",
    "print(\"\\nTargeted statistical test results:\")\n",
    "\n",
    "for tmin, tmax in time_windows:\n",
    "    cond1_df = long_words.copy().crop(tmin, tmax).to_data_frame(index=index)\n",
    "    cond2_df = short_words.copy().crop(tmin, tmax).to_data_frame(index=index)\n",
    "    \n",
    "    for elec in elecs:\n",
    "        # extract data\n",
    "        A = cond1_df[elec].groupby(\"condition\").mean()\n",
    "        B = cond2_df[elec].groupby(\"condition\").mean() # change that\n",
    "\n",
    "        # conduct t test\n",
    "        t, p = ttest_rel(A, B) # Paired t-test\n",
    "\n",
    "        # display results\n",
    "        format_dict = dict(\n",
    "            elec=elec, tmin=tmin, tmax=tmax, df=len(epochs.events) - 2, t_val=t, p=p\n",
    "        )\n",
    "        print(report.format(**format_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4149e4",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_obs, clusters, p_values, _ = cluster_stats # change that\n",
    "\n",
    "p_accept = 0.001\n",
    "good_pval_inds = np.where(p_values < p_accept)[0]\n",
    "\n",
    "# configure variables for visualization\n",
    "colors = \"r\",'steelblue'\n",
    "linestyles = '-', '--'\n",
    "\n",
    "times = evoked_contrast.times * 1e3\n",
    "\n",
    "# Prepare mask for topomaps\n",
    "ch_inds = []\n",
    "\n",
    "for i, chan in enumerate(evoked_contrast_all_chan.info['ch_names']):\n",
    "    if roi in evoked_contrast_all_chan.info['ch_names'][i] :    \n",
    "        ch_inds.append(i)\n",
    "        \n",
    "# loop over clusters\n",
    "for i_clu, clu_idx in enumerate(good_pval_inds):\n",
    "    \n",
    "    evoked_contrast_topo = evoked_contrast_all_chan.copy()\n",
    "\n",
    "    # unpack cluster information, get unique indices\n",
    "    time_inds = clusters[clu_idx]\n",
    "    time_inds = np.unique(time_inds)\n",
    "    sig_times = evoked_contrast.times[time_inds]\n",
    "    \n",
    "    # initialize figure\n",
    "    fig, ax_topo = plt.subplots(1, 1, figsize=(17, 5))\n",
    "    \n",
    "    evoked_contrast_topo.crop(tmin=sig_times[0], tmax=sig_times[-1])\n",
    "    \n",
    "    # create spatial mask\n",
    "    mask = np.zeros((evoked_contrast_all_chan.get_data().shape[0], evoked_contrast_topo.times.shape[0]), dtype=bool)\n",
    "    mask[ch_inds, :] = True\n",
    "\n",
    "    \n",
    "    evoked_contrast_topo.plot_topomap(times='peaks', mask=mask, axes=ax_topo, cmap='bwr',\n",
    "                        cnorm = matplotlib.colors.CenteredNorm(vcenter=0), show=False,\n",
    "                        colorbar=False, mask_params=dict(markersize=10), extrapolate='head',\n",
    "                        sphere=(0, 0.019, 0, 0.184))\n",
    "\n",
    "    image = ax_topo.images[0]\n",
    "\n",
    "    # remove the title that would otherwise say \"0.000 s\"\n",
    "    ax_topo.set_title(\"\")\n",
    "\n",
    "    # create additional axes (for ERF and colorbar)\n",
    "    divider = make_axes_locatable(ax_topo)\n",
    "\n",
    "    # add axes for colorbar\n",
    "    ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    plt.colorbar(image, cax=ax_colorbar)\n",
    "\n",
    "    # add new axis for time courses and plot time courses\n",
    "    ax_signals = divider.append_axes('right', size='300%', pad=1.2)\n",
    "\n",
    "    title = 'Cluster #{0}, (p={1})'.format(i_clu + 1, p_values[clu_idx])\n",
    "\n",
    "    plot_compare_evokeds(evokeds, title=title,\n",
    "                    colors=colors, show=False,axes=ax_signals,\n",
    "                    split_legend=True, truncate_yaxis='auto', combine=\"mean\")\n",
    "\n",
    "    # plot temporal cluster extent\n",
    "    ymin, ymax = ax_signals.get_ylim()\n",
    "    ax_signals.fill_betweenx((ymin, ymax), sig_times[0], sig_times[-1],\n",
    "                        color='orange', alpha=0.3)\n",
    "    # clean up viz\n",
    "    mne.viz.tight_layout(fig=fig)\n",
    "    fig.subplots_adjust(bottom=.05)\n",
    "    \n",
    "    del evoked_contrast_topo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
