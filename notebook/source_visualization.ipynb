{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f981dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import pickle\n",
    "from src.params import MRI_PATH, SUBJ_CLEAN, RESULT_PATH\n",
    "from src.utils import get_bids_file\n",
    "from src.config import subjects_dir\n",
    "import numpy as np\n",
    "from scipy import stats as stats\n",
    "from mne.stats import spatio_temporal_cluster_1samp_test, summarize_clusters_stc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d02f85",
   "metadata": {},
   "source": [
    "## Test average condition per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97263c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/claraelk/scratch/laughter_data/results/meg/reports/sub-01/sub-01_task-LaughterActive_run-all_AR_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 7 columns\n",
      "296 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Cond1 73\n",
      "Cond2 74\n",
      "73\n",
      "74\n",
      "All subj cond1 : 73\n",
      "All subj cond2 : 74\n",
      "Reading /home/claraelk/scratch/laughter_data/results/meg/reports/sub-02/sub-02_task-LaughterActive_run-all_AR_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 7 columns\n",
      "295 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Cond1 75\n",
      "Cond2 72\n",
      "148\n",
      "146\n",
      "All subj cond1 : 221\n"
     ]
    }
   ],
   "source": [
    "####### PREPARE DATA #######\n",
    "\n",
    "# Loop through subjects\n",
    "all_subject_stcs_cond1 = []\n",
    "all_subject_stcs_cond2 = []\n",
    "\n",
    "all_stc_cond1 = []\n",
    "all_stc_cond2 = []\n",
    "\n",
    "group_all_stc_cond1 = []\n",
    "group_all_stc_cond2 = []\n",
    "\n",
    "task = 'LaughterActive'\n",
    "cond1_name = 'LaughReal'\n",
    "cond2_name = 'LaughPosed'\n",
    "\n",
    "for subj in ['01', '02']:\n",
    "    _, epo_path = get_bids_file(RESULT_PATH, task=task, subj=subj, stage=\"AR_epo\")\n",
    "    epochs = mne.read_epochs(epo_path)\n",
    "\n",
    "    # Find condition related to epoch\n",
    "    cond1_epo = []\n",
    "    cond2_epo = []\n",
    "    for i, epo_arr in enumerate(epochs.events): \n",
    "        if epo_arr[2] == 3 :                \n",
    "            cond1_epo.append(i)\n",
    "        elif epo_arr[2] == 2 : \n",
    "            cond2_epo.append(i)\n",
    "\n",
    "    cond1 = [str(nb).zfill(3) for nb in cond1_epo]\n",
    "    cond2 = [str(nb).zfill(3) for nb in cond2_epo]\n",
    "    print('Cond1', len(cond1))\n",
    "    print('Cond2', len(cond2))\n",
    "\n",
    "    for epo1 in cond1 : \n",
    "        stc_path_cond1 = os.path.join(MRI_PATH, f'sub-{subj}', 'src',\n",
    "                                      f'{epo1}_MNE_source-stc.h5')\n",
    "        \n",
    "        stc_cond1 = mne.read_source_estimate(stc_path_cond1)\n",
    "        all_stc_cond1.append(stc_cond1)\n",
    "\n",
    "    for epo2 in cond2 : \n",
    "        stc_path_cond2 = os.path.join(MRI_PATH, f'sub-{subj}', 'src',\n",
    "                                      f'{epo2}_MNE_source-stc.h5')\n",
    "        \n",
    "        stc_cond2 = mne.read_source_estimate(stc_path_cond2)\n",
    "        all_stc_cond2.append(stc_cond2)\n",
    "\n",
    "    print(len(all_stc_cond1)) \n",
    "    print(len(all_stc_cond2))  \n",
    "\n",
    "    ######## AVERAGE SIGNAL PER CONDITION FOR 1 SUBJ #########\n",
    "    for subject_stcs1 in all_stc_cond1 : \n",
    "\n",
    "        # Average the SourceEstimates for the current subject\n",
    "        avg_data_cond1 = np.mean([s.data for s in all_stc_cond1], axis=0)\n",
    "        avg_stc_cond1 = mne.SourceEstimate(avg_data_cond1, \n",
    "                                           vertices=stc_cond1.vertices, \n",
    "                                           tmin=stc_cond1.tmin, \n",
    "                                           tstep=stc_cond1.tstep, \n",
    "                                           subject='sub-all')\n",
    "\n",
    "        # Append to the list for all subjects\n",
    "        all_subject_stcs_cond1.append(avg_stc_cond1)\n",
    "\n",
    "    print('All subj cond1 :', len(all_subject_stcs_cond1))\n",
    "\n",
    "\n",
    "    for subject_stcs2 in all_stc_cond2 : \n",
    "\n",
    "        # Average the SourceEstimates for the current subject\n",
    "        avg_data_cond2 = np.mean([s.data for s in all_stc_cond2], axis=0)\n",
    "        avg_stc_cond2 = mne.SourceEstimate(avg_data_cond1, \n",
    "                                           vertices=stc_cond2.vertices, \n",
    "                                           tmin=stc_cond2.tmin, \n",
    "                                           tstep=stc_cond2.tstep, \n",
    "                                           subject='sub-all')\n",
    "\n",
    "        # Append to the list for all subjects\n",
    "        all_subject_stcs_cond2.append(avg_stc_cond2)\n",
    "\n",
    "    print('All subj cond2 :', len(all_subject_stcs_cond2))\n",
    "\n",
    "    # Average 1 subject CONDITION 1\n",
    "    group_avg_data_cond1 = np.mean([s.data for s in all_subject_stcs_cond1], axis=0)\n",
    "    group_avg_stc_cond1 = mne.SourceEstimate(group_avg_data_cond1, \n",
    "                                             vertices=avg_stc_cond1.vertices, \n",
    "                                             tmin=avg_stc_cond1.tmin, \n",
    "                                             tstep=avg_stc_cond1.tstep, \n",
    "                                             subject=avg_stc_cond1.subject)\n",
    "\n",
    "    # Average 1 subject CONDITION 2\n",
    "    group_avg_data_cond2 = np.mean([s.data for s in all_subject_stcs_cond2], axis=0)\n",
    "    group_avg_stc_cond2 = mne.SourceEstimate(group_avg_data_cond2, \n",
    "                                             vertices=avg_stc_cond2.vertices, \n",
    "                                             tmin=avg_stc_cond2.tmin, \n",
    "                                             tstep=avg_stc_cond2.tstep, \n",
    "                                             subject=avg_stc_cond2.subject)\n",
    "    \n",
    "    group_all_stc_cond1.append(group_avg_stc_cond1.data)\n",
    "    group_all_stc_cond2.append(group_avg_stc_cond2.data)\n",
    "    \n",
    "print(np.array(group_all_stc_cond1).shape)\n",
    "print(np.array(group_all_stc_cond2).shape)\n",
    "# SAVE STC GROUPE !!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4fcc4",
   "metadata": {},
   "source": [
    "## Import data averaged per subject for each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2489e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_data = []\n",
    "group_all_stc_cond1 = []\n",
    "group_all_stc_cond2 =[]\n",
    "\n",
    "task = 'LaughterActive'\n",
    "cond1_name = 'LaughReal'\n",
    "cond2_name = 'LaughPosed'\n",
    "conditions = cond1_name +'-'+ cond2_name\n",
    "\n",
    "for subj in SUBJ_CLEAN :\n",
    "    filename_contrast, _ = get_bids_file(RESULT_PATH, subj=subj, task=task, stage='erp-morph-contrast', condition=conditions)\n",
    "    filename_cond1, _ = get_bids_file(RESULT_PATH, subj=subj, task=task, stage='erp-morph-contrast', condition=cond1_name)\n",
    "    filename_cond2, _ = get_bids_file(RESULT_PATH, subj=subj, task=task, stage='erp-morph-contrast', condition=cond2_name)\n",
    "\n",
    "    save_contrasts = os.path.join(MRI_PATH, 'sub-all', filename_contrast)\n",
    "\n",
    "    save_cond1 = os.path.join(MRI_PATH, 'sub-all', filename_cond1)\n",
    "    save_cond2 = os.path.join(MRI_PATH, 'sub-all', filename_cond2)\n",
    "\n",
    "    with open(save_contrasts, 'rb') as f:\n",
    "        contrast_subj = pickle.load(f)  \n",
    "\n",
    "    with open(save_cond1, 'rb') as f:\n",
    "        group_all_stc_cond1_subj = pickle.load(f)  \n",
    "\n",
    "    with open(save_cond2, 'rb') as f:\n",
    "        group_all_stc_cond2_subj = pickle.load(f) \n",
    "   \n",
    "    contrast_data.append(contrast_subj)\n",
    "    group_all_stc_cond1.append(group_all_stc_cond1_subj[0])\n",
    "    group_all_stc_cond2.append(group_all_stc_cond2_subj[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde1745b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 20484, 2401)\n"
     ]
    }
   ],
   "source": [
    "contrast = np.array(group_all_stc_cond1)-np.array(group_all_stc_cond2) \n",
    "print(contrast.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4835a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_mask = np.isnan(contrast)\n",
    "if np.any(nan_mask):\n",
    "    print(\"Warning: NaN values found in the data. Please address and rerun the analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55bbc243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.53779361e-12,  3.81587687e-12,  2.63271323e-12, ...,\n",
       "          1.10993472e-12,  1.43488986e-12, -3.59507710e-14],\n",
       "        [ 8.45745976e-12,  4.79072361e-12, -1.15936286e-12, ...,\n",
       "         -3.54733353e-12, -2.08827148e-12,  3.84516369e-13],\n",
       "        [-2.16348922e-13,  1.62012105e-12,  2.76746839e-12, ...,\n",
       "          4.35638990e-12,  5.31320680e-12,  4.90813267e-12],\n",
       "        ...,\n",
       "        [-5.44717023e-12,  6.50602911e-12,  1.56201246e-11, ...,\n",
       "         -5.68071313e-12, -7.49380801e-12, -4.72773386e-12],\n",
       "        [ 6.59459740e-13,  8.36739926e-12,  1.36615135e-11, ...,\n",
       "         -5.16555219e-13, -2.40325228e-12, -2.59317666e-12],\n",
       "        [ 7.82818872e-12,  1.04150593e-11,  1.02371069e-11, ...,\n",
       "          3.91017450e-12,  3.46622077e-12,  2.08843185e-12]],\n",
       "\n",
       "       [[-3.11219823e-13, -2.13149289e-14,  6.44996106e-13, ...,\n",
       "          2.15698986e-12,  2.76738064e-12,  1.52956718e-12],\n",
       "        [-1.51869318e-12, -3.05755996e-12, -2.48448956e-12, ...,\n",
       "          3.80789912e-12,  2.34643991e-12,  1.19192793e-12],\n",
       "        [ 8.88654980e-13,  1.27089628e-12,  1.27497874e-12, ...,\n",
       "          3.49437398e-13,  1.38658221e-12,  2.92269928e-12],\n",
       "        ...,\n",
       "        [-1.22681539e-11, -1.11069158e-11, -8.69286902e-12, ...,\n",
       "         -2.29745044e-12, -3.43934710e-12, -5.32678238e-12],\n",
       "        [-1.51687390e-11, -1.47847934e-11, -1.10833491e-11, ...,\n",
       "         -3.02081045e-12, -4.24894620e-12, -6.27420355e-12],\n",
       "        [-1.63165635e-11, -1.64506813e-11, -1.16987813e-11, ...,\n",
       "         -2.85471447e-12, -3.75888786e-12, -5.06957310e-12]],\n",
       "\n",
       "       [[ 8.40852149e-13,  2.95975609e-12,  1.75715916e-12, ...,\n",
       "         -8.74823270e-12, -1.27245975e-11, -1.49750913e-11],\n",
       "        [-8.46759941e-13,  2.11295097e-12,  3.36983602e-12, ...,\n",
       "         -3.94380229e-13, -1.09653703e-12, -2.51922280e-12],\n",
       "        [-7.13007237e-12, -4.23325809e-12, -2.79374645e-12, ...,\n",
       "         -2.53135685e-12, -1.31358407e-12, -1.75474368e-12],\n",
       "        ...,\n",
       "        [ 4.68601248e-13, -9.67596869e-13, -6.51060284e-13, ...,\n",
       "          4.93561005e-12,  7.04319852e-12,  8.84711463e-12],\n",
       "        [-2.25118604e-12, -6.05211877e-12, -6.60435696e-12, ...,\n",
       "          1.81921264e-12,  4.88008375e-12,  4.04072498e-12],\n",
       "        [-5.30913862e-12, -9.68951111e-12, -1.04782574e-11, ...,\n",
       "         -2.45977675e-12,  1.26416297e-12, -1.24470654e-12]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 3.03029463e-12,  2.23059093e-12,  3.56181576e-12, ...,\n",
       "         -5.63800438e-12, -4.92516915e-12, -2.64560209e-12],\n",
       "        [-7.67653706e-12, -7.67527254e-12, -8.30558513e-12, ...,\n",
       "          9.76399390e-13,  5.19534940e-13, -8.18440475e-13],\n",
       "        [-1.58975900e-12, -3.26473475e-12, -4.11868954e-12, ...,\n",
       "         -1.36187763e-12, -2.26058765e-12, -1.75367623e-12],\n",
       "        ...,\n",
       "        [ 5.92847193e-12,  6.25098367e-12,  8.41610671e-12, ...,\n",
       "          1.74584773e-12,  2.15472011e-13,  1.13635530e-12],\n",
       "        [ 7.77746871e-12,  7.37758951e-12,  7.87125002e-12, ...,\n",
       "          2.97953799e-12,  5.96582151e-14,  4.29139658e-13],\n",
       "        [ 1.08361738e-11,  9.24289568e-12,  7.24827952e-12, ...,\n",
       "          3.68758487e-12, -3.04384965e-13, -1.15083556e-12]],\n",
       "\n",
       "       [[-3.09658123e-13,  7.45202722e-13, -1.97252846e-13, ...,\n",
       "          2.79276749e-12,  3.96944642e-12,  5.05316453e-12],\n",
       "        [-6.11421246e-12, -5.26738566e-12,  8.26083577e-13, ...,\n",
       "          3.53312006e-12,  3.36458894e-12,  2.20767952e-12],\n",
       "        [ 1.30414944e-11,  1.16577876e-11,  7.75328526e-12, ...,\n",
       "         -7.11664206e-12, -5.91039286e-12, -4.35769617e-12],\n",
       "        ...,\n",
       "        [ 3.09990527e-12,  6.86957351e-13,  2.38575442e-12, ...,\n",
       "          1.30005731e-11,  1.09918400e-11,  3.48892805e-12],\n",
       "        [ 2.50269102e-12,  3.05228189e-13,  3.96789063e-12, ...,\n",
       "          8.68487228e-12,  4.97936504e-12, -2.93513947e-12],\n",
       "        [ 1.75850572e-12,  1.83881738e-12,  6.56159852e-12, ...,\n",
       "          4.20175420e-12, -3.88082780e-13, -7.68242887e-12]],\n",
       "\n",
       "       [[ 1.53530727e-12,  1.72935696e-12,  1.77111555e-12, ...,\n",
       "         -1.33018495e-13, -2.21071318e-13, -5.46841138e-13],\n",
       "        [ 6.37347655e-13,  5.82895335e-13,  7.60527288e-13, ...,\n",
       "         -3.92141459e-13, -2.96299535e-13,  5.66997317e-14],\n",
       "        [-2.66208370e-13,  8.74733672e-13,  1.68919125e-12, ...,\n",
       "          1.07233908e-12,  9.61062772e-13,  4.84010077e-13],\n",
       "        ...,\n",
       "        [ 9.23807752e-13, -6.65327868e-14,  6.23447572e-13, ...,\n",
       "         -1.40048149e-13, -1.32344887e-12, -3.14789346e-13],\n",
       "        [ 2.63612341e-12,  2.15550140e-12,  2.97187710e-12, ...,\n",
       "         -5.11854506e-13, -2.40921395e-12, -1.66681244e-12],\n",
       "        [ 4.06303166e-12,  3.99586932e-12,  4.62964241e-12, ...,\n",
       "         -1.17758616e-12, -3.28523889e-12, -2.54589484e-12]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbdcc4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value: -2.0679515313825692e-25\n",
      "Max value: 2.0679515313825692e-25\n"
     ]
    }
   ],
   "source": [
    "print(\"Min value:\", np.min(contrast))\n",
    "print(\"Max value:\", np.max(contrast))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab274b4e",
   "metadata": {},
   "source": [
    "## Compute adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "885d688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading inverse operator decomposition from /home/claraelk/scratch/laughter_data/results/mri/sub-01/src/sub-01-mag-oct6-inv.fif...\n",
      "    Reading inverse operator info...\n",
      "    [done]\n",
      "    Reading inverse operator decomposition...\n",
      "    [done]\n",
      "    270 x 270 full covariance (kind = 1) found.\n",
      "    Noise covariance matrix read.\n",
      "    24585 x 24585 diagonal covariance (kind = 2) found.\n",
      "    Source covariance matrix read.\n",
      "    24585 x 24585 diagonal covariance (kind = 6) found.\n",
      "    Orientation priors read.\n",
      "    24585 x 24585 diagonal covariance (kind = 5) found.\n",
      "    Depth priors read.\n",
      "    Did not find the desired covariance matrix (kind = 3)\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Source spaces transformed to the inverse solution coordinate frame\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "surface source space present ...\n",
      "Computing morph matrix...\n",
      "    Left-hemisphere map read.\n",
      "    Right-hemisphere map read.\n",
      "    18 smooth iterations done.\n",
      "    14 smooth iterations done.\n",
      "[done]\n",
      "[done]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# We have to change the shape for the dot() to work properly\\nX = X.reshape(n_vertices_sample, n_times * n_subjects * 2)\\nprint(\"Morphing data.\")\\nX = morph_mat.dot(X)  # morph_mat is a sparse matrix\\nX = X.reshape(n_vertices_fsave, n_times, n_subjects, 2)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the source space we are morphing to\n",
    "src_fname = '/home/claraelk/scratch/laughter_data/results/mri/anat/subjects/fsaverage/bem/fsaverage-5-src.fif'\n",
    "fname_inv = os.path.join(MRI_PATH, 'sub-01', 'src', 'sub-01-mag-oct6-inv.fif')\n",
    "inverse_operator = mne.minimum_norm.read_inverse_operator(fname_inv)\n",
    "\n",
    "src = mne.read_source_spaces(src_fname)\n",
    "fsave_vertices = [s[\"vertno\"] for s in src]\n",
    "morph_mat = mne.compute_source_morph(\n",
    "    src=inverse_operator[\"src\"],\n",
    "    subject_to=\"fsaverage\",\n",
    "    spacing=fsave_vertices,\n",
    "    subjects_dir=subjects_dir,\n",
    ").morph_mat\n",
    "\n",
    "n_vertices_fsave = morph_mat.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjects = 27\n",
    "\n",
    "\n",
    "# We have to change the shape for the dot() to work properly\n",
    "group_cond1 = np.array(group_all_stc_cond1)\n",
    "group_cond1 = group_cond1.reshape(n_vertices_sample, n_times * n_subjects)\n",
    "print(\"Morphing data.\")\n",
    "group_cond1 = morph_mat.dot(group_cond1)  # morph_mat is a sparse matrix\n",
    "group_cond1 = group_cond1.reshape(n_vertices_fsave, n_times, n_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05c31448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20484\n"
     ]
    }
   ],
   "source": [
    "print(n_vertices_fsave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0134805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_src = 'sub-02-mag-oct6-inv.fif'\n",
    "path_src = os.path.join(MRI_PATH, 'sub-02', 'src', file_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba0d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "<class 'mne.source_space.SourceSpaces'>\n"
     ]
    }
   ],
   "source": [
    "src_fname = '/home/claraelk/scratch/laughter_data/results/mri/anat/subjects/fsaverage/bem/fsaverage-5-src.fif'\n",
    "\n",
    "src = mne.read_source_spaces(src_fname)\n",
    "print(type(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1a760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing adjacency.\n",
      "-- number of adjacent vertices : 20484\n"
     ]
    }
   ],
   "source": [
    "# Find adjacency\n",
    "print(\"Computing adjacency.\")\n",
    "adjacency = mne.spatial_src_adjacency(src, dist=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c89d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20484, 20484)\n"
     ]
    }
   ],
   "source": [
    "print(adjacency.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f93e2",
   "metadata": {},
   "source": [
    "## Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a92e770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 2401, 20484)\n",
      "27\n",
      "Clustering.\n",
      "Using a threshold of 2.055529\n",
      "stat_fun(H1): min=-6.911754 max=6.263853\n",
      "2 disjoint adjacency sets found\n",
      "Running initial clustering â€¦\n",
      "Found 38009 clusters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429c461f3d1545439b09c7fbcdc2763e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/1023 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Now let's actually do the clustering. This can take a long time...\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClustering.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m T_obs, clusters, cluster_p_values, H0 \u001b[38;5;241m=\u001b[39m clu \u001b[38;5;241m=\u001b[39m \u001b[43mspatio_temporal_cluster_1samp_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43madjacency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjacency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_permutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_down_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_disjoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-358>:10\u001b[0m, in \u001b[0;36mspatio_temporal_cluster_1samp_test\u001b[0;34m(X, threshold, n_permutations, tail, stat_fun, adjacency, n_jobs, seed, max_step, spatial_exclude, step_down_p, t_power, out_type, check_disjoint, buffer_size, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/mne/stats/cluster_level.py:1285\u001b[0m, in \u001b[0;36mspatio_temporal_cluster_1samp_test\u001b[0;34m(X, threshold, n_permutations, tail, stat_fun, adjacency, n_jobs, seed, max_step, spatial_exclude, step_down_p, t_power, out_type, check_disjoint, buffer_size, verbose)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1284\u001b[0m     exclude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpermutation_cluster_1samp_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstat_fun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_permutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_permutations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjacency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_down_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_down_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_power\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_power\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_disjoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_disjoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-357>:12\u001b[0m, in \u001b[0;36mpermutation_cluster_1samp_test\u001b[0;34m(X, threshold, n_permutations, tail, stat_fun, adjacency, n_jobs, seed, max_step, exclude, step_down_p, t_power, out_type, check_disjoint, buffer_size, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/mne/stats/cluster_level.py:1212\u001b[0m, in \u001b[0;36mpermutation_cluster_1samp_test\u001b[0;34m(X, threshold, n_permutations, tail, stat_fun, adjacency, n_jobs, seed, max_step, exclude, step_down_p, t_power, out_type, check_disjoint, buffer_size, verbose)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Non-parametric cluster-level paired t-test.\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \n\u001b[1;32m   1142\u001b[0m \u001b[38;5;124;03mFor details, see :footcite:p:`MarisOostenveld2007,Sassenhagen2019`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;124;03m.. footbibliography::\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m stat_fun, threshold \u001b[38;5;241m=\u001b[39m _check_fun(X, stat_fun, threshold, tail)\n\u001b[0;32m-> 1212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_permutation_cluster_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_permutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_permutations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstat_fun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjacency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_down_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_down_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_power\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_power\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_disjoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_disjoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/mne/stats/cluster_level.py:986\u001b[0m, in \u001b[0;36m_permutation_cluster_test\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    980\u001b[0m     this_include \u001b[38;5;241m=\u001b[39m step_down_include\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProgressBar(\n\u001b[1;32m    983\u001b[0m     iterable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(orders)),\n\u001b[1;32m    984\u001b[0m     mesg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPermuting\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextra\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    985\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[0;32m--> 986\u001b[0m     H0 \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmy_do_perm_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis_include\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mt_power\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplit_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43morders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# include original (true) ordering\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tail \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# up tail\u001b[39;00m\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/mne/stats/cluster_level.py:738\u001b[0m, in \u001b[0;36m_do_1samp_permutations\u001b[0;34m(X, slices, threshold, tail, adjacency, stat_fun, max_step, include, partitions, t_power, orders, sample_shape, buffer_size, progress_bar)\u001b[0m\n\u001b[1;32m    735\u001b[0m     t_obs_surr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m sample_shape\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# Find cluster on randomized stats\u001b[39;00m\n\u001b[0;32m--> 738\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43m_find_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_obs_surr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjacency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mt_power\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_power\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m perm_clusters_sums \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(perm_clusters_sums) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# get max with sign info\u001b[39;00m\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/mne/stats/cluster_level.py:440\u001b[0m, in \u001b[0;36m_find_clusters\u001b[0;34m(x, threshold, tail, adjacency, max_step, include, partitions, t_power, show_info)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_in \u001b[38;5;129;01min\u001b[39;00m x_ins:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(x_in):\n\u001b[0;32m--> 440\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43m_find_clusters_1dir_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_power\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mndimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m         clusters \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    444\u001b[0m         sums\u001b[38;5;241m.\u001b[39mappend(out[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/mne/stats/cluster_level.py:495\u001b[0m, in \u001b[0;36m_find_clusters_1dir_parts\u001b[0;34m(x, x_in, adjacency, max_step, partitions, t_power, ndimage)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(np\u001b[38;5;241m.\u001b[39mmax(partitions) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    494\u001b[0m     x_i \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogical_and(x_in, partitions \u001b[38;5;241m==\u001b[39m p)\n\u001b[0;32m--> 495\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43m_find_clusters_1dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_power\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mndimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     clusters \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    498\u001b[0m     sums\u001b[38;5;241m.\u001b[39mappend(out[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/mne/stats/cluster_level.py:541\u001b[0m, in \u001b[0;36m_find_clusters_1dir\u001b[0;34m(x, x_in, adjacency, max_step, t_power, ndimage)\u001b[0m\n\u001b[1;32m    539\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m _get_components(x_in, adjacency)\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(adjacency, \u001b[38;5;28mlist\u001b[39m):  \u001b[38;5;66;03m# use temporal adjacency\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m \u001b[43m_get_clusters_st\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madjacency must be a sparse matrix or list\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/mne/stats/cluster_level.py:275\u001b[0m, in \u001b[0;36m_get_clusters_st\u001b[0;34m(x_in, neighbors, max_step)\u001b[0m\n\u001b[1;32m    273\u001b[0m     keepers[row[start]] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msort(col[start:end])\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_clusters_st_1step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeepers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_clusters_st_multistep(keepers, neighbors,\n\u001b[1;32m    278\u001b[0m                                       max_step)\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/mne/stats/cluster_level.py:177\u001b[0m, in \u001b[0;36m_get_clusters_st_1step\u001b[0;34m(keepers, neighbors)\u001b[0m\n\u001b[1;32m    175\u001b[0m clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(keepers):\n\u001b[0;32m--> 177\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[43m_get_clusters_spatial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ci, cl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(c):\n\u001b[1;32m    179\u001b[0m         check[ii, cl] \u001b[38;5;241m=\u001b[39m ci \u001b[38;5;241m+\u001b[39m enum_offset\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/mne/stats/cluster_level.py:139\u001b[0m, in \u001b[0;36m_get_clusters_spatial\u001b[0;34m(s, neighbors)\u001b[0m\n\u001b[1;32m    137\u001b[0m ind \u001b[38;5;241m=\u001b[39m t_inds[icount \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# look across other vertices\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m buddies \u001b[38;5;241m=\u001b[39m \u001b[43m_get_buddies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m t_inds\u001b[38;5;241m.\u001b[39mextend(buddies)\n\u001b[1;32m    141\u001b[0m icount \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/mne/stats/cluster_level.py:30\u001b[0m, in \u001b[0;36m_get_buddies_fallback\u001b[0;34m(r, s, neighbors, indices)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     buddies \u001b[38;5;241m=\u001b[39m indices[r[indices]]\n\u001b[0;32m---> 30\u001b[0m buddies \u001b[38;5;241m=\u001b[39m buddies[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbuddies\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massume_unique\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m]\n\u001b[1;32m     31\u001b[0m r[buddies] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m buddies\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36min1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/numpy/lib/arraysetops.py:667\u001b[0m, in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert, kind)\u001b[0m\n\u001b[1;32m    663\u001b[0m     ar1_upper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mint\u001b[39m(ar1_max), \u001b[38;5;28mint\u001b[39m(ar2_max))\n\u001b[1;32m    664\u001b[0m     ar1_lower \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(ar1_min), \u001b[38;5;28mint\u001b[39m(ar2_min))\n\u001b[1;32m    666\u001b[0m     range_safe_from_overflow \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m((\n\u001b[0;32m--> 667\u001b[0m         ar1_upper \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(ar2_min) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmax,\n\u001b[1;32m    668\u001b[0m         ar1_lower \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(ar2_min) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(ar1\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mmin\n\u001b[1;32m    669\u001b[0m     ))\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# Optimal performance is for approximately\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# log10(size) > (log10(range) - 2.27) / 0.927.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# However, here we set the requirement that by default\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# arrays. See discussion on \u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/12065.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    680\u001b[0m     range_safe_from_overflow \u001b[38;5;129;01mand\u001b[39;00m \n\u001b[1;32m    681\u001b[0m     (below_memory_constraint \u001b[38;5;129;01mor\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    682\u001b[0m ):\n",
      "File \u001b[0;32m~/notebook/lib/python3.8/site-packages/numpy/core/getlimits.py:675\u001b[0m, in \u001b[0;36miinfo.__init__\u001b[0;34m(self, int_type)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mitemsize \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid integer data type \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind,))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Note that X needs to be a multi-dimensional array of shape\n",
    "# observations (subjects) Ã— time Ã— space, so we permute dimensions\n",
    "X = np.transpose(contrast, [0, 2, 1])\n",
    "print(X.shape)\n",
    "n_subjects = len(contrast)\n",
    "print(n_subjects)\n",
    "\n",
    "# Here we set a cluster forming threshold based on a p-value for\n",
    "# the cluster based permutation test.\n",
    "# We use a two-tailed threshold, the \"1 - p_threshold\" is needed\n",
    "# because for two-tailed tests we must specify a positive threshold.\n",
    "p_threshold = 0.001\n",
    "df = n_subjects - 1  # degrees of freedom for the test\n",
    "t_threshold = stats.distributions.t.ppf(1 - p_threshold / 2, df=df)\n",
    "\n",
    "# Now let's actually do the clustering. This can take a long time...\n",
    "print(\"Clustering.\")\n",
    "T_obs, clusters, cluster_p_values, H0 = clu = spatio_temporal_cluster_1samp_test(\n",
    "    X,\n",
    "    adjacency=adjacency,\n",
    "    n_jobs=-1,\n",
    "    threshold=None,\n",
    "    buffer_size=None,\n",
    "    verbose=True,\n",
    "    n_permutations=1024,\n",
    "    tail=0,\n",
    "    step_down_p = 0.05,\n",
    "    check_disjoint=True,\n",
    "    out_type='indices'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd1e8536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loeading cluster\n"
     ]
    }
   ],
   "source": [
    "print('Loading cluster')\n",
    "save_cluster_stats, _ = get_bids_file(RESULT_PATH, stage = \"erp-source\", task=task, measure=\"Ttest-clusters\", condition = conditions)\n",
    "\n",
    "path_save_cluster = os.path.join(MRI_PATH, 'sub-all', save_cluster_stats)\n",
    "\n",
    "with open(path_save_cluster, 'rb') as f:\n",
    "    clu = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35a62377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "T_obs, clusters, cluster_p_values, H0 = clu \n",
    "\n",
    "# Select the clusters that are statistically significant at p < 0.05\n",
    "good_clusters_idx = np.where(cluster_p_values < 0.05)[0]\n",
    "good_clusters = [clusters[idx] for idx in good_clusters_idx]\n",
    "print(good_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7bf5e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38009,)\n"
     ]
    }
   ],
   "source": [
    "print(cluster_p_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "866f39a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22851562 0.34960938 0.57421875 0.609375   0.98339844 0.99511719\n",
      " 0.99707031 0.99804688 0.99902344 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(cluster_p_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2eb729f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(good_clusters_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11afb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
